# é¡¹ç›®è®¾æƒ³<br>
<font size=4>

1. ä½¿ç”¨ç›®æ ‡æ£€æµ‹å’Œäººä½“å…³é”®ç‚¹æ£€æµ‹è·å¾—æ é“ƒè½¨è¿¹å’Œå•ä¾§ä¸‹è‚¢å…³èŠ‚çš„ä½ç½®
2. è®¡ç®—å„ä¸ªæ—¶åˆ»è†å…³èŠ‚é«‹å…³èŠ‚çš„è§’åº¦å’ŒåŠ›è‡‚
3. è¾…åŠ©è§‚å¯Ÿæ˜¯å¦å­˜åœ¨ä¸è‰¯åŠ›è‡‚


```python
# æŸ¥çœ‹å½“å‰æŒ‚è½½çš„æ•°æ®é›†ç›®å½•, è¯¥ç›®å½•ä¸‹çš„å˜æ›´é‡å¯ç¯å¢ƒåä¼šè‡ªåŠ¨è¿˜åŸ
# View dataset directory. 
# This directory will be recovered automatically after resetting environment. 
!ls /home/aistudio/data
```

    data103531



```python
# æŸ¥çœ‹å·¥ä½œåŒºæ–‡ä»¶, è¯¥ç›®å½•ä¸‹çš„å˜æ›´å°†ä¼šæŒä¹…ä¿å­˜. è¯·åŠæ—¶æ¸…ç†ä¸å¿…è¦çš„æ–‡ä»¶, é¿å…åŠ è½½è¿‡æ…¢.
# View personal work directory. 
# All changes under this directory will be kept even after reset. 
# Please clean unnecessary files in time to speed up environment loading. 
!ls /home/aistudio/work
```

    001.mp4  dataset  mp4_img  output



```python
#è§£å‹ç›®æ ‡æ£€æµ‹æ•°æ®é›†
!unzip -oq /home/aistudio/data/data103531/DatasetId_215201_1628403652.zip -d squat_detect
```


```python
# å‡†å¤‡ä¸€äº›å¯èƒ½ç”¨åˆ°çš„å·¥å…·åº“
import xml.etree.cElementTree as ET
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import math
import paddle.fluid as fluid
import time
import random
```


```python
# å¯¼å…¥paddlex
!pip install paddlex
```


```python
# ä½¿ç”¨paddlexè¿›è¡Œæ•°æ®é›†çš„åˆ’åˆ†è®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†.
# åœ¨æ­¤ä¹‹å‰è¯·å°†squat_detect/DatasetId_215201_1628403652/ä¸‹çš„imagesæ–‡ä»¶å¤¹æ”¹ä¸ºJPEGImages
!paddlex --split_dataset --format VOC --dataset_dir squat_detect/DatasetId_215201_1628403652 --val_value 0.2 --test_value 0.01
```

    Dataset Split Done.[0m
    [0mTrain samples: 284[0m
    [0mEval samples: 71[0m
    [0mTest samples: 3[0m
    [0mSplit files saved in squat_detect/DatasetId_215201_1628403652[0m
    [0m[0m


```python
#å°†æ•°æ®é›†è½¬åˆ°work/dataset/ï¼Œä¸“é—¨å­˜æ”¾å’Œå¤„ç†æ•°æ®é›†çš„æ–‡ä»¶
!cp -r squat_detect/DatasetId_215201_1628403652 work/dataset/
```


```python
# è°ƒæ•´ä¸‹æ ‡æ³¨æ–‡ä»¶å‘½åï¼Œä¸é»˜è®¤çš„ä¸€è‡´ï¼ˆå¤„ç†æˆç›¸åŒæ–‡ä»¶åï¼‰
#labels.txtæ”¹åä¸ºlabel_list.txt
!mv work/dataset/labels.txt work/dataset/label_list.txt
```

# ç”¨paddleXè®­ç»ƒä¸€ä¸ªæ é“ƒç‰‡çš„ç›®æ ‡æ£€æµ‹æ¨¡å‹

## <font size=4> **è®¾ç½®transform**


```python
import paddlex as pdx
from paddlex.det import transforms
train_transforms = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.Normalize(),
    transforms.ResizeByShort(short_size=800, max_size=1333),
    transforms.Padding(coarsest_stride=32)
])

eval_transforms = transforms.Compose([
    transforms.Normalize(),
    transforms.ResizeByShort(short_size=800, max_size=1333),
    transforms.Padding(coarsest_stride=32),
])
```

## <font size=4>**è¯»æ•°æ®**



```python
train_dataset = pdx.datasets.VOCDetection(
    data_dir='work/dataset/',
    file_list='work/dataset/train_list.txt',
    label_list='work/dataset/label_list.txt',
    transforms=train_transforms,
    shuffle=True)
eval_dataset = pdx.datasets.VOCDetection(
    data_dir='work/dataset/',
    file_list='work/dataset/val_list.txt',
    label_list='work/dataset/label_list.txt',
    transforms=eval_transforms)
```

    2021-08-13 17:45:24 [INFO]	Starting to read file list from dataset...
    2021-08-13 17:45:25 [INFO]	284 samples in file work/dataset/train_list.txt
    creating index...
    index created!
    2021-08-13 17:45:25 [INFO]	Starting to read file list from dataset...
    2021-08-13 17:45:25 [INFO]	71 samples in file work/dataset/val_list.txt
    creating index...
    index created!


## <font size=4>**è®­ç»ƒ**


```python
num_classes = len(train_dataset.labels)
model = pdx.det.YOLOv3(num_classes=num_classes, backbone='MobileNetV1')
model.train(
    num_epochs=70,
    train_dataset=train_dataset,
    train_batch_size=8,
    eval_dataset=eval_dataset,
    learning_rate=0.000125,
    lr_decay_epochs=[210, 240],
    save_interval_epochs=20,
    save_dir='work/output/yolov3_MobileNetV1',
    use_vdl=True)
```

<font size=4>**çœ‹çœ‹ç»“æœå¦‚ä½•**


```python
import paddlex as pdx
model = pdx.load_model('work/output/yolov3_MobileNetV1/best_model')
image_name='work/mp4_img/145.jpg'#è¦å¤„ç†çš„å›¾ç‰‡
result = model.predict(image_name)

pdx.det.visualize(image_name, result, threshold=0.1, save_dir='./')#å¯ä»¥è°ƒæ•´é˜ˆå€¼
```

    2021-08-14 19:19:51 [INFO]	Model[YOLOv3] loaded.
    2021-08-14 19:19:53 [INFO]	The visualized result is saved as ./visualize_145.jpg



```python
from matplotlib.image import imread
import matplotlib.pyplot as plt

def show_img(img_path, size=8):

    im = imread(img_path)
    plt.figure(figsize=(size,size))
    plt.axis("off")
    plt.imshow(im)

#æŸ¥çœ‹åˆšæ‰çš„å›¾ç‰‡
show_img('visualize_145.jpg')
```


![png](output_18_0.png)


 **å“å…ˆå‡‘åˆç€ç”¨å§**

# è·å¾—æ é“ƒç‰‡ä¸­ç‚¹çš„åæ ‡


```python
import paddlex as pdx
import math

model = pdx.load_model('work/output/yolov3_MobileNetV1/best_model')

def get_wp(image_name, model):
    
    result = model.predict(image_name)
    #print(result)
    '''
    ç­›é€‰å‡ºscoreæœ€å¤§çš„weight_plateçš„bboxåæ ‡
    '''
    weight_plate_box = []
    for i in range(len(result)):
        if result[i]['category']=='weight_plate':
            weight_plate_box.append(result[i])
    #print(weight_plate_box)

    max_ = weight_plate_box[0]['bbox']
    for k in range(len(weight_plate_box)-1):
        if weight_plate_box[k]['score'] < weight_plate_box[k+1]['score']:
            max_ = weight_plate_box[k+1]['bbox']
    #print(max_)

    weight_plate = [math.ceil((max_[0]+max_[2])/2), math.ceil((max_[1]+max_[3])/2)]
    return weight_plate

get_wp(image_name='squat_detect/DatasetId_215201_1628403652/JPEGImages/110.jpeg', model=model)
```

    2021-08-13 18:44:25 [INFO]	Model[YOLOv3] loaded.





    [185, 226]



## **ä¹Ÿå¯ä»¥è¯•ä¸€è¯•çº¯ç‰¹å¾å·¥ç¨‹çš„æ¨¡æ¿åŒ¹é…æ³•**


```python
import cv2
from matplotlib import pyplot as plt
import math

def track(img_, template_, is_show=False):

    img=cv2.imread(img_,0)
    template=cv2.imread(template_,0)

    w, h = template.shape[::-1]
    methods = 'cv2.TM_SQDIFF_NORMED'
    method = eval(methods)
    res = cv2.matchTemplate(img,template,method)
    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res) #æ‰¾åˆ°æœ€å¤§å€¼å’Œæœ€å°å€¼
    if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:
        top_left = min_loc
    else:
        top_left = max_loc
    bottom_right = (top_left[0] + w, top_left[1] + h)
    cv2.rectangle(img,top_left, bottom_right, 255, 5)

    if is_show==True:
        print('top_left=', top_left, 'bottom_right=', bottom_right)
        plt.subplot(122),plt.imshow(img,cmap = 'gray')
        plt.title('Detected Point'), plt.xticks([]), plt.yticks([])
        plt.show()
    
    return [math.ceil(top_left[0]/2+bottom_right[0]/2), math.ceil(top_left[1]/2+bottom_right[1]/2)]

track(img_='work/mp4_img/150.jpg', template_='./muban.png', is_show=True)
```

    top_left= (237, 440) bottom_right= (309, 511)



![png](output_23_1.png)





    [273, 476]



# äººä½“å…³é”®ç‚¹æ£€æµ‹

**å®‰è£…PaddleHub**


```python
!pip install paddlehub==2.0.0b1 -i https://pypi.tuna.tsinghua.edu.cn/simple
```


```python
import cv2
import os
import paddlehub as hub
import matplotlib.pyplot as plt
from matplotlib.image import imread
import numpy as np
%matplotlib inline
```

## å°†è§†é¢‘ä¸­æ¯ä¸€å¸§ä¿å­˜æˆå›¾ç‰‡


```python
def transform_video_to_image(video_file_path, img_path):
    '''
    å°†è§†é¢‘ä¸­æ¯ä¸€å¸§ä¿å­˜æˆå›¾ç‰‡
    '''
    video_capture = cv2.VideoCapture(video_file_path)
    fps = video_capture.get(cv2.CAP_PROP_FPS)
    count = 0
    while(True):
        ret, frame = video_capture.read() 
        if ret:
            cv2.imwrite(img_path + '%d.jpg' % count, frame)
            count += 1
        else:
            break
    video_capture.release()
    print('è§†é¢‘å›¾ç‰‡ä¿å­˜æˆåŠŸ, å…±æœ‰ %d å¼ ' % count)
    return fps
```


```python
%cd work/
!mkdir mp4_img
%cd ..
```

    /home/aistudio/work
    /home/aistudio



```python
# ç´ æè§†é¢‘ä½ç½®
input_video = 'work/001.mp4'

# å°†è§†é¢‘ä¸­æ¯ä¸€å¸§ä¿å­˜æˆå›¾ç‰‡
fps = transform_video_to_image(input_video, 'work/mp4_img/')
```

    è§†é¢‘å›¾ç‰‡ä¿å­˜æˆåŠŸ, å…±æœ‰ 720 å¼ 


## **éå†work/mp4_img è·å¾—äººä½“å…³é”®ç‚¹**
<font size=4> 
  
* **paddlex + paddlehub**    æ—¶é—´é•¿ï¼Œå¿ä¸€ä¸‹
* **æ¨¡æ¿åŒ¹é… + paddlehub**

äºŒé€‰ä¸€å³å¯


```python
'''
æ–¹æ³•ä¸€ï¼špaddlex + paddlehub
'''
import paddlehub as hub
pose_estimation = hub.Module(name="human_pose_estimation_resnet50_mpii")
model = pdx.load_model('work/output/yolov3_MobileNetV1/best_model')

def get_keypoints(input_frame_path, output_frame_path, model_):
    keypoints = []
    file_items = os.listdir(input_frame_path)
    '''
    æŒ‰ç…§æ—¶é—´é¡ºåºéå†
    '''
    for i in range(len(file_items)):
        Path=[os.path.join(input_frame_path, str(i)+'.jpg')]
        print(Path)
        weight_plate = get_wp(image_name=Path[0], model=model_)
        result = pose_estimation.keypoint_detection(paths=Path,visualization=False)
        #result = pose_estimation.keypoint_detection(paths=Path,visualization=False, output_dir=output_frame_path) #è¾“å‡ºå¯è§†åŒ–å›¾ç‰‡å°†ä¿å­˜åœ¨'work/pose_img/'
        
        keypoints.append([result[0]['data']['left_hip'][0], result[0]['data']['left_hip'][1],#è®°å½•é«‹çš„åæ ‡
                        result[0]['data']['left_knee'][0], result[0]['data']['left_knee'][1],#è®°å½•è†çš„åæ ‡
                        result[0]['data']['left_ankle'][0], result[0]['data']['left_ankle'][1],#è®°å½•è¸çš„åæ ‡
                        weight_plate[0], weight_plate[1]])#è®°å½•æ é“ƒä¸­å¿ƒçš„åæ ‡
        
    return keypoints

key_points = get_keypoints(input_frame_path='work/mp4_img/', output_frame_path='work/pose_img/', model_=model)

'''
å†™å…¥csvï¼Œä¸ºé˜²æ­¢ä»£ç æ‰§è¡Œå™¨è‡ªåŠ¨é‡å¯ï¼Œå¯¼è‡´key_pointsä¸¢å¤±
'''
import csv

with open('./key_points.csv', 'w', newline='') as csvfile:
    writer  = csv.writer(csvfile)
    for row in key_points:
        writer.writerow(row)

```


```python
'''
æ–¹æ³•äºŒï¼šæ¨¡æ¿åŒ¹é… + paddlehub
'''
import os
import paddlehub as hub
pose_estimation = hub.Module(name="human_pose_estimation_resnet50_mpii")

def get_keypoints(input_frame_path, output_frame_path):
    keypoints = []
    file_items = os.listdir(input_frame_path)
    '''
    æŒ‰ç…§æ—¶é—´é¡ºåºéå†
    '''
    for i in range(len(file_items)):
        Path=[os.path.join(input_frame_path, str(i)+'.jpg')]
        print(Path)
        weight_plate = track(img_=Path[0], template_='./muban.png')
        result = pose_estimation.keypoint_detection(paths=Path,visualization=False)
        #result = pose_estimation.keypoint_detection(paths=Path,visualization=False, output_dir=output_frame_path) #è¾“å‡ºå¯è§†åŒ–å›¾ç‰‡å°†ä¿å­˜åœ¨'work/pose_img/'
        
        keypoints.append([result[0]['data']['left_hip'][0], result[0]['data']['left_hip'][1],#è®°å½•é«‹çš„åæ ‡
                        result[0]['data']['left_knee'][0], result[0]['data']['left_knee'][1],#è®°å½•è†çš„åæ ‡
                        result[0]['data']['left_ankle'][0], result[0]['data']['left_ankle'][1],#è®°å½•è¸çš„åæ ‡
                        weight_plate[0], weight_plate[1]])#è®°å½•æ é“ƒä¸­å¿ƒçš„åæ ‡
        
    return keypoints

key_points = get_keypoints(input_frame_path='work/mp4_img/', output_frame_path='work/pose_img/')

import csv #å†™å…¥csv
with open('./key_points.csv', 'w', newline='') as csvfile:
    writer  = csv.writer(csvfile)
    for row in key_points:
        writer.writerow(row)
```

<font size=4>**å†â„¢ä»csvè¯»å‡ºæ¥**


```python
import csv
with open("key_points.csv") as f:
    reader = csv.reader(f)
    key_points=[row for row in  reader]
    for i in range(len(key_points)):
        for j in range(8):
            key_points[i][j] = int(key_points[i][j])
            
print(key_points[2])
```

    [272, 480, 311, 600, 266, 710, 286, 418]


<font size=4>**è®¡ç®—è†å…³èŠ‚è§’åº¦**


```python
import math
import numpy as np

def get_knee_angle(key_points):
    knee_angle_list = []
    for i in key_points:
        '''
        é€šè¿‡å‘é‡ç®—å‡ºè†è§’çš„coså€¼ï¼Œå†ç”¨åä¸‰è§’å‡½æ•°å¾—åˆ°è§’åº¦
        '''
        dot = (i[2]-i[0]) * (i[2]-i[4]) + (i[3]-i[1]) * (i[3]-i[5])
        m = math.sqrt(((i[2]-i[0])**2) + (i[3]-i[1])**2) * math.sqrt(((i[2]-i[4])**2) + (i[3]-i[5])**2)
        knee_angle = (180/math.pi) * np.arccos(dot/m)
        print(knee_angle)
        knee_angle_list.append(knee_angle)
    return knee_angle_list

y = get_knee_angle(key_points)
x = np.linspace(start=0, stop=len(y)+1, num=len(y))

```


```python
print("len_x",len(x))
import matplotlib.pyplot as plt
plt.plot(x,y,'r',label='knee_angle',linewidth=2,alpha=1)
```

    len_x 720





    [<matplotlib.lines.Line2D at 0x7efd3029b250>]




![png](output_39_2.png)


<font size=4>**æ¯›åˆºæ¯”è¾ƒå¤šï¼Œè¯•è¯•å·´ç‰¹æ²ƒæ–¯ä½é€šæ»¤æ³¢**


```python
from scipy import signal

b, a = signal.butter(1, 0.1, 'lowpass')
filtedData1 = signal.filtfilt(b, a, y)

plt.plot(x,filtedData1,'r',label='knee_angle',linewidth=2, alpha=1)
#ä¿å­˜å›¾ç‰‡
plt.savefig("knee_angle.jpg")
```


![png](output_41_0.png)


 <font size=4> **è®¡ç®—è†å…³èŠ‚è§’é€Ÿåº¦**

ç”¨åä¸€å¸§å‡å‰ä¸€å¸§è¡¨ç¤º


```python
import copy

Y = copy.deepcopy(filtedData1.tolist())
Y.append(filtedData1[-1])
print(len(filtedData1))
print(len(Y))
'''
æŠŠè§’åº¦yæ‹·è´ä¸€ä»½ï¼Œåœ¨Yæœ€åæ’ä¸€ä¸ªy[-1]ï¼Œé¿å…ç›¸å‡å¯¼è‡´é•¿åº¦ä¸åŒ¹é…
'''
angular_velocity = []

for i in range(len(filtedData1)):
    angular_velocity.append(Y[i+1] - Y[i])

#æ˜¾ç¤ºè†å…³èŠ‚é€Ÿåº¦
plt.plot(x,angular_velocity,'r',label='angular_velocity',linewidth=2,alpha=0.8)
```

    720
    721





    [<matplotlib.lines.Line2D at 0x7efdf77c0590>]




![png](output_43_2.png)


# å¯¼å‡ºè§†é¢‘

## <font size=3> å…ˆå¹³æ»‘æ‰€æœ‰ç‚¹


```python
import numpy as np
import matplotlib.pyplot as plt
from scipy import signal
hip_x, hip_y, knee_x, knee_y, ankle_x, ankle_y, plate_x, plate_y= [],[],[],[],[],[],[],[]
for i in range(len(key_points)):
    hip_x.append(key_points[i][0])
    hip_y.append(key_points[i][1])
    knee_x.append(key_points[i][2])
    knee_y.append(key_points[i][3])
    ankle_x.append(key_points[i][4])
    ankle_y.append(key_points[i][5])
    plate_x.append(key_points[i][6])
    plate_y.append(key_points[i][7])

hip_x = signal.savgol_filter(hip_x,21,3)
hip_y = signal.savgol_filter(hip_y,21,3)
knee_x = signal.savgol_filter(knee_x,21,3)
knee_y = signal.savgol_filter(knee_y,21,3)
ankle_x = signal.savgol_filter(ankle_x,21,3)
ankle_y = signal.savgol_filter(ankle_y,21,3)
plate_x = signal.savgol_filter(plate_x,21,3)
plate_y = signal.savgol_filter(plate_y,21,3)

plt.plot(x, plate_y, 'r', label='knee_angle', linewidth=1, alpha=1)

x = np.linspace(start=0, stop=len(key_points), num=len(key_points))
plt.plot(x, hip_x, 'r', label='knee_angle', linewidth=1, alpha=1)
```




    [<matplotlib.lines.Line2D at 0x7efe0c037a10>]




![png](output_46_1.png)


## <font size=3> å†ç»˜åˆ¶å›¾ç‰‡


```python
!mkdir picture
```


```python
import cv2
import numpy as np
from math import ceil

for i in range(len(key_points)):
    I=np.zeros((800,500),dtype=np.uint8)+255
    I=cv2.cvtColor(I,cv2.COLOR_GRAY2BGR)
    I = cv2.circle(I, (ceil(hip_x[i]), ceil(hip_y[i])), 8, (0,0,255), 0)#é«‹
    I = cv2.circle(I, (ceil(knee_x[i]), ceil(knee_y[i])), 8, (0,0,255), 0)#è†
    I = cv2.circle(I, (ceil(ankle_x[i]), ceil(ankle_y[i])), 8, (0,0,255), 0)#è¸
    I = cv2.circle(I, (ceil(plate_x[i]), ceil(plate_y[i])), 8, (0,0,255), 0)#æ é“ƒ
    
    
    I = cv2.line(I,(ceil(hip_x[i]), ceil(hip_y[i])),(ceil(knee_x[i]), ceil(knee_y[i])), color=(255,0,0),thickness=5)
    I = cv2.line(I,(ceil(knee_x[i]), ceil(knee_y[i])),(ceil(ankle_x[i]), ceil(ankle_y[i])), color=(255,0,0),thickness=5)
    I = cv2.line(I,(ceil(hip_x[i]), ceil(hip_y[i])),(ceil(plate_x[i])+5, ceil(plate_y[i])+5), color=(255,0,0),thickness=5)
    # ä»ï¼ˆï¼‰-ã€‹ï¼ˆï¼‰é¢œè‰²ï¼ˆBGR è“ï¼‰å®½åº¦æ˜¯5

    cv2.imwrite('./picture/'+str(i)+'.jpg', I)
```

##  <font size=3> æœ€åå›¾ç‰‡åˆæˆè§†é¢‘


```python
import cv2
import os

def combine_image_to_video(comb_path, output_file_path, fps=30, is_print=False):
    '''
        åˆå¹¶å›¾åƒåˆ°è§†é¢‘
    '''
    fourcc = cv2.VideoWriter_fourcc(*'MP4V')    
    
    file_items = os.listdir(comb_path)
    file_len = len(file_items)
    # print(comb_path, file_items)
    if file_len > 0 :
        temp_img = cv2.imread(os.path.join(comb_path, file_items[0]))
        img_height, img_width = temp_img.shape[0], temp_img.shape[1]
        
        out = cv2.VideoWriter(output_file_path, fourcc, fps, (img_width, img_height))

        for i in range(file_len):
            pic_name = os.path.join(comb_path, str(i)+".jpg")
            if is_print:
                print(i+1,'/', file_len, ' ', pic_name)
            img = cv2.imread(pic_name)
            out.write(img)
        out.release()
```


```python
# åˆå¹¶å›¾åƒåˆ°è§†é¢‘
combine_image_to_video('picture/', 'output.mp4', fps=20)
```

# æ€»ç»“ä¸åæ€
<font size=5>
  
* ç”¨paddleXåšç›®æ ‡æ£€æµ‹çš„æ•ˆæœå…¶å®ä¸å¤ªç†æƒ³ï¼Œæ¨¡æ¿åŒ¹é…è¦å¥½ä¸€äº›ã€‚
* ç”±äºåœºæ™¯é‡Œæœ‰åœ†å½¢çš„ç¯ï¼Œè°ƒè¯•é˜¶æ®µè¿˜å‡ºç°è¿‡ä¸‹é¢çš„æƒ…å†µ
  
<img src="https://ai-studio-static-online.cdn.bcebos.com/4749e41636674bc4a0de48caec98dbbcd01de6a69ae04d25895dac4a9a665ff1" height="660" width="380" >
  
* åœºæ™¯æ¯”è¾ƒç®€å•ï¼Œä½†å¯èƒ½æ˜¯ç”±äºæ é“ƒç‰‡é®æŒ¡äº†ä¸Šè‚¢ï¼Œå¯¼è‡´paddlehubå¯¹é«‹å…³èŠ‚çš„æ£€æµ‹ä¸å¤ªç†æƒ³ã€‚å¦‚æœå…ˆæ£€æµ‹æ é“ƒç‰‡ï¼Œåœ¨åŸå›¾ä¸Šæ‹¼æ¥ä¸ŠåŠèº«ï¼Œè¯´ä¸å®šä¼šæ›´å¥½ã€‚

<img src="https://ai-studio-static-online.cdn.bcebos.com/4eb911aca78a4d4badf29b5c5ea0602cba3d39cf66264595b0ec8ed84d6359ac" height="330" width="190" >



è¯·ç‚¹å‡»[æ­¤å¤„](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)æŸ¥çœ‹æœ¬ç¯å¢ƒåŸºæœ¬ç”¨æ³•.  <br>
Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. 
